\documentclass[letterpaper,12pt,oneside,onecolumn]{article}
\usepackage[margin=1in, bottom=1in, top=1in]{geometry} %1 inch margins
\usepackage{amsmath, amssymb, amstext}
\usepackage{fancyhdr}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{theorem}
\usepackage{tikz}
\usepackage{tkz-berge}

%Macros
\newcommand{\A}{\mathbb{A}} \newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}} \newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}} \newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}} \newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
 
 
\newcommand{\cA}{\mathcal{A}} \newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}} \newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}} \newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}} \newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}} \newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}} \newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}} \newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}} \newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}} \newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}} \newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}} \newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}} \newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}} \newcommand{\cZ}{\mathcal{Z}}

\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}


\newenvironment{proof}{{\bf Proof:  }}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofof}[1]{{\bf Proof of #1:  }}{\hfill\rule{2mm}{2mm}}
\newenvironment{proofofnobox}[1]{{\bf#1:  }}{}\newenvironment{example}{{\bf Example:  }}{\hfill\rule{2mm}{2mm}}

%\renewcommand{\thesection}{\lecnum.\arabic{section}}
%\renewcommand{\theequation}{\thesection.\arabic{equation}}
%\renewcommand{\thefigure}{\thesection.\arabic{figure}}

\newtheorem{fact}{Fact}[section]
\newtheorem{lemma}[fact]{Lemma}
\newtheorem{theorem}[fact]{Theorem}
\newtheorem{definition}[fact]{Definition}
\newtheorem{corollary}[fact]{Corollary}
\newtheorem{proposition}[fact]{Proposition}
\newtheorem{claim}[fact]{Claim}
\newtheorem{exercise}[fact]{Exercise}
\newtheorem{note}[fact]{Note}
\newtheorem{conjecture}[fact]{Conjecture}

\newcommand{\size}[1]{\ensuremath{\left|#1\right|}}
\newcommand{\ceil}[1]{\ensuremath{\left\lceil#1\right\rceil}}
\newcommand{\floor}[1]{\ensuremath{\left\lfloor#1\right\rfloor}}

%END MACROS
%Page style
\pagestyle{fancy}

\listfiles

\raggedbottom

\lhead{\today}
\rhead{W. Justin Toth CS761-Randomized Algorithms Assignment 4} %CHANGE n to ASSIGNMENT NUMBER ijk TO COURSE CODE
\renewcommand{\headrulewidth}{1pt} %heading underlined
%\renewcommand{\baselinestretch}{1.2} % 1.2 line spacing for legibility (optional)

\begin{document}
%Problem 1
\section{}
\paragraph{}
Let $G=(V,E)$ be a directed graph, let $s,t\in V$ be source and sink vertices respectively and let $k$ be a positive integer. We may assume that $\delta^{in}(s) = \delta^{out}(t) = \emptyset$. Let $x_f \in [0,1]^E$ be a fractional $s-t$ flow on $G$ of value $k$. That is, $x_f$ satisfies the equations
$$ x_f(\delta^{out}(s)) = x_f(\delta^{in}(t)) = k$$
and
$$x_f(\delta^{in}(v)) = x_f(\delta^{out}(v))$$
for all $v \in V\backslash\{s,t\}$.
\paragraph{}
We're going to need some concepts from network flow theory before we move on. Lucky our flow being $0$-$1$ simplifies things quite a bit. Given a digraph $D$ and a flow $x \in \{0,1\}^E$ we define the residual digraph $D_x$ as follows: 
\begin{itemize}
\item$V(D_x) = V(D)$
\item for every arc $uv \in E(D)$ if $x(uv) = 0$ add arc $uv$ to $E(D_x)$. We call such arcs ``forward" arcs.
\item for every arc $uv \in E(D)$ if $x(uv) = 1$ add arc $vu$ to $E(D_x)$. we call such arcs ``backward" arcs.
\end{itemize} 
An $s-t$ path in $D_x$ is called an \emph{augmenting path}. It is an easy observation to see that if $x$ is a flow of value $k$ and $P$ is an augmenting path in $D_x$, then we can obtain a flow of value $k+1$ by increasing $x(e)$ from $0$ to $1$ for every forward arc in $P$, and decreasing $x(e)$ from $1$ to $0$ for every backward arc in $P$. Using the max-flow min-cut theorem we can see that if there is no augmenting path in $D_x$ then $x$ is a maximum flow. Simply take the cut $S$ defined by vertices reachable from $s$ in $D_x$ (this is an $s-t$ cut since $t$ is not reachable). Since there is no augmenting paths, all forward arcs in $\delta^{out}(S)$ are saturated (have $x$-value $1$). So the value of $x$ is at least (and hence equal to) the capacity of cut $S$, implying that $x$ is a maximum flow.
\paragraph{}
Our algorithm will maintain an integral flow in every step, and a weighting on the residual digraph so that (an auxiliary graph closely related to) the residual digraph is weighted-Eulerian. This will allow us to efficiently use random walks to identify augmenting paths for our flow. Due to our fractional flow $x_f$ we know that we will always be able to find such a path while the value of $x$ is less than $k$, as we are sure $x$ is not maximum.
\paragraph{}
We will need one more auxiliary graph before we describe the algorithm. Let $D'_x$ be the digraph obtained from $D_x$ by adding a special vertex $b$, and two arcs: $tb$ and $bs$. It is immediate that $D_x$ has an augmenting path if and only if $D_x'$ as cycle containing $b$.
\paragraph{Weighting}
If $x$ is an integral $s-t$ flow on $G$ we can define an Eulerian weighting on $D'_x$ as follows. For every forward arc $uv \in E(D_x)$ let $w(uv) = x_f(uv)$. For every backward arc $vu \in E(D_x)$ let $w(vu) = 1- x_f(uv)$. Let $k'$ be the value of $x$. Let $w(tb) = w(bs) = k-k'$.
\begin{claim}
Let $x_0=0,x_1, \dots, x_{k-1}\in \{0,1\}^E$ be integral $s-t$ flows on $G$ such that $x_{i+1}$ is obtained from $x_i$ by augmenting $x_i$ along an augmenting path in $D_{x_i}$. Let $w_0,w_1,\dots, w_{k-1}$ be the weightings of each respective $D'_{x_i}$. Then for all $i$
$$w_i(\delta^{out}(v)) = w_i(\delta^{in}(v))$$ for all $v \in V(D'_{x_i})$.
\end{claim}
\begin{proof}
We proceed by induction on $i$. In the base case $i = 0$. Then $D_{x_i} = G$ and $D'_{x_i} = G + \{bs, tb\}$. We have $w_i(e) = x_f(e)$ for all $e \in E(D_{x_i})$ and since $x_f$ is a flow the claim holds for all $v \in V(D_{x_i})\backslash\{s,t\}$. For vertex $s$,
$$w_i(\delta^{out}(s)) = x_f(\delta^{out}(s)) = k = w_i(bs) = w_i(\delta^{in}(s)).$$
The proof of the claim follows similarly for vertex $t$. By definition the claim always holds for vertex $b$. Hence we have proven the base case.
\paragraph{}
Now in the inductive step we suppose the claims holds for $x_0, \dots, x_{i-1}$ and consider $x_i$ with $i \geq 1$. Let $P$ be the augmenting path used to obtain $x_i$ from $x_{i-1}$. The digraph $D'_{x_i}$ is obtained from $D'_{x_{i-1}}$ by flipping the orientation of every arc along $P$.

\paragraph{} If $v \not\in V(P) \cup \{b\}$ then by induction the claim already holds at $v$. Further by definition the claim always holds at $b$. So it remains to verify the claim on vertices of $P$. Let $v \in V(P)\backslash\{s,t\}$. Suppose $uv, vx \in E(P)$. Then we have
\begin{align*}
w_i(\delta^{in}(v)) &= w_{i-1}(\delta^{in}(v)) -x_f(uv) + 1-x_f(vx)\\
&=w_{i-1}(\delta^{out}(v)) + 1-x_f(uv) -x_f(vx) \\
&=w_i(\delta^{out}(v)).
\end{align*}
So the claim holds for all such $v$. For vertex $s$, let $sy \in E(P)$. We have
$$w_i(\delta^{in}(s)) = w_{i-1}(\delta^{in}(s)) -1 + 1-x_f(sy) = w_{i-1}(\delta^{out}(s)) -x_f(sy) = w_i(\delta^{out}(s))$$
and so the claim holds for $s$. The proof for $t$ follows similarly to the proof for $s$.
\end{proof}
\paragraph{Algorithm}
We initialize our algorithm with integral flow $x = 0$. Our algorithm iterates the following step until our flow $x$ has value $k$ (which it then returns). Let $w$ be the associated weighting on $D'_{x} = G + \{tb,bs\}$. Perform a random walk on $D'_x$ starting from $b$ with transition probability of arc $uv$, $P_{uv}$ equal to 
$$P_{uv} = \frac{w(uv)}{w(\delta^{out}(u))}.$$
End this random walk when you return to $b$. The walk has identified an augmenting path $P$. Augment flow of $x$ along $P$ and repeat.
\paragraph{}
The expected time to find an augmenting path in any iteration is equal to $H_{b,b}$, the hitting time of $b,b$. We have that $H_{b,b} = \frac{1}{\pi_b}$ where $\pi_b$ is the probability of being in $b$ in the stationary distribution.
\begin{claim}
	Let $W_x = w(E(D'_x))$. For any $v \in V(D'_x)$, $\pi_v = \frac{w(\delta^{out}(v))}{W_x}$.
\end{claim}
\begin{proof}
	We calculate
	$$\pi_v = \sum_{u: uv \in E(D'_x)} \pi_uP_{uv} = \sum_{u:uv \in E(D'_x)} \frac{w(\delta^{out}(u))}{W_x}\frac{w(uv)}{w(\delta^{out}(u))} = \frac{w(\delta^{in}(v))}{W_x} = \frac{w(\delta^{out}(v))}{W_x} = \pi_v$$
	with the second last equality following from out previous Claim. Since 
	$$\sum_{v \in V(D'_x)} \pi_v = \sum_{v\in V(D'_x)} \frac{w(\delta^{out}(v))}{W_x} = \frac{W_x}{W_x} = 1$$
	this is the unique stationary distribution.
\end{proof}
\paragraph{}
From this Claim above we see that $H_{b,b} = \frac{W_x}{w(\delta^{out}(b))}$ at each iteration of the algorithm.
In iteration $i$, $w(\delta^{out}(b)) = w(bs) = k-i$ since $i$ is the value of flow $x$ in iteration $i$. Since $w(e)$ is at most $1$ for each $e$ in the edge set of $G$, and $w(e) \leq k\leq |E(G)|$ for $bs, tb$. Hence $W_x \leq 2m$ where $m = |E(G)|$. Therefore in iteration $i$,
$$H_{b,b} \leq \frac{2m}{k-i}.$$
\paragraph{}
So the total expected running time is at most
$$\sum_{i=0}^k\frac{m}{k-i} = m\log k \leq m\log m.$$
Thus the running time $\tilde{O}(|E|)$ as desired.$\blacksquare$
\newpage
%Problem 2
\section{}
\paragraph{}
Consider an instance $I$ of $k$SAT with $n$ variables $x_1,\dots,x_n$ and $m$ clauses $C_1, \dots, C_m$. We solve it using the following generalization of Sch\"oning's Algorithm:
\begin{enumerate}
	\item Repeat up to $N$ times, terminating if all clauses of $I$ are satisfied:
	\begin{enumerate}
		\item Start with a random initial assignment
		\item Repeat up to $kn$ steps, terminating if all clauses satisfied: switch the value of a random variable in an unsatisfied clause.
	\end{enumerate}
	\item Return a satisfying assignment if it is found; otherwise return ``unsatisfiable".
\end{enumerate}
\paragraph{}
Let $S$ be a satisfying assignment. Let $A_i$ be the assignment in the $i$-th step of the algorithm. Let $X_i$ be the number of variables that have the same value in $A_i$ and $S$. If $X_i = n$ then $A_i = S$ and hence we are done.
\newpage
%Problem 3
\section{}

\newpage
%Problem 4
\section{}

\newpage
%Problem 5
\section{}

\newpage
%Problem 6
\section{}
\end{document}
